{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925f72ae",
   "metadata": {},
   "source": [
    "# Task \n",
    "requirements\n",
    "yfinance\n",
    "numpy\n",
    "pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Fin Data Sources\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "#Data viz\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    " \n",
    "import time\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "df = pd.read_html(url)[0]\n",
    "df.loc[:, \"Date added\"] = pd.to_datetime(df[\"Date added\"])\n",
    "df.loc[:, \"year\"] = pd.to_datetime(df[\"Date added\"]).dt.year\n",
    "group = df.groupby(\"year\").agg({\n",
    "    \"Symbol\": lambda x: x.notna().sum()\n",
    "})\n",
    "group.sort_values(\"Symbol\", ascending=False)\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0732aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"year since\"] = date.today().year -  pd.to_datetime(df[\"Date added\"]).dt.year\n",
    "filtered_df = df.loc[(df[\"year since\"] > 20) & (df[\"year\"] > 1957)].sort_values(\"year since\", ascending=False)\n",
    "print(\"How many companies are in the index for more than 20 year\", len(filtered_df))\n",
    "filtered_df.reset_index(inplace=True)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c04a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "data = pd.read_html(url, header=[0, 1])[1]\n",
    "\n",
    "# Safely assign datetime to the original DataFrame\n",
    "date_col = pd.to_datetime(data[('Date', 'Date')])\n",
    "data.loc[:, ('Date', 'Date')] = date_col\n",
    "\n",
    "# Now extract year and compute year difference\n",
    "data.loc[:, ('Date', 'year')] = date_col.dt.year\n",
    "data.loc[:, ('Date', 'year since')] = date.today().year - date_col.dt.year\n",
    "\n",
    "# Check result\n",
    "filtered = data.loc[data[('Date', 'year since')] > 20]\n",
    "filtered.sort_values(('Date', 'year since'), ascending=False)\n",
    "print(\"how may companies are in the index more than 20 years: \", len(filtered))\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5c24c",
   "metadata": {},
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbebd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "end = date(2025, 5, 1) # As of May 1\n",
    "start = date(2025, 1,1 )\n",
    "print(f'Year = {end.year}; month= {end.month}; day={end.day}')\n",
    "print(f'Period for indexes: {start} to {end} ')\n",
    "\n",
    "def get_ytd_value(ticket:str, start:datetime.date=date(2025, 1, 1), end:datetime.date=date(2025,5 ,1 )):\n",
    "    \"\"\"return the YTD from a ticket from yahoo finance in %\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = yf.download(\n",
    "        tickers = ticket,\n",
    "        start=start, \n",
    "        end=end,\n",
    "        interval = \"1d\")\n",
    "    ytd = (df[( 'Close', ticket)].iloc[-1]/df[( 'Close', ticket)].iloc[0] -1)*100\n",
    "    return float(ytd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {\n",
    "    \"USA\": \"^GSPC\",                         # S&P 500\n",
    "    \"China\": \"000001.SS\",                   # Shanghai Composite\n",
    "    \"Hong Kong\": \"^HSI\",                    # Hang Seng Index\n",
    "    \"Australia\": \"^AXJO\",                   # S&P/ASX 200\n",
    "    \"India\": \"^NSEI\",                       # Nifty 50\n",
    "    \"Canada\": \"^GSPTSE\",                    # S&P/TSX Composite\n",
    "    \"Germany\": \"^GDAXI\",                    # DAX\n",
    "    \"United Kingdom\": \"^FTSE\",              # FTSE 100\n",
    "    \"Japan\": \"^N225\",                       # Nikkei 225\n",
    "    \"Mexico\": \"^MXX\",                       # IPC Mexico\n",
    "    \"Brazil\": \"^BVSP\"                       # Ibovespa\n",
    "}\n",
    "\n",
    "data = []\n",
    "\n",
    "for country, ticket in countries.items():\n",
    "    ytd = get_ytd_value(ticket)\n",
    "    data.append({\n",
    "        \"Country\": country,\n",
    "        \"Ticket\": ticket,\n",
    "        \"YTD\": ytd\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get USA YTD for comparison\n",
    "usa_ytd = df.loc[df[\"Country\"] == \"USA\", \"YTD\"].values[0]\n",
    "\n",
    "# Calculate difference from USA\n",
    "df[\"S&P Diff\"] = df[\"YTD\"] - usa_ytd\n",
    "\n",
    "# Optional: sort by difference\n",
    "df = df.sort_values(\"S&P Diff\", ascending=False)\n",
    "df.reset_index(inplace=True)\n",
    "del df[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994a1ed",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "\n",
    "    Download S&P 500 historical data (1950-present) using yfinance\n",
    "    Identify all-time high points (where price exceeds all previous prices)\n",
    "    For each pair of consecutive all-time highs, find the minimum price in between\n",
    "    Calculate drawdown percentages: (high - low) / high Ã— 100\n",
    "    Filter for corrections with at least 5% drawdown\n",
    "    Calculate the duration in days for each correction period\n",
    "    Determine the 25th, 50th (median), and 75th percentiles for correction durations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(\n",
    "    tickers = \"^GSPC\",\n",
    "    start=date(1950, 1, 1), \n",
    "    end=date.today(),\n",
    "    interval = \"1d\")[\"Close\"]\n",
    "df.loc[:, \"cummax\"] = df[\"^GSPC\"].cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8fd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an empty DataFrame to collect corrections with >5% drawdown\n",
    "corrections_df = pd.DataFrame()\n",
    "\n",
    "for i in df[\"cummax\"].unique():\n",
    "    filtered_df = df[df[\"cummax\"] == i].copy()\n",
    "\n",
    "    filtered_df[\"diff\"] = np.round((1 - filtered_df[\"^GSPC\"] / filtered_df[\"cummax\"]) * 100, 1)\n",
    "\n",
    "    low_row = filtered_df.loc[filtered_df[\"^GSPC\"].idxmin()] \n",
    "    min_price = low_row[\"^GSPC\"]\n",
    "\n",
    "    high_prices = filtered_df[\"cummax\"]\n",
    "    filtered_df[\"drawdown\"] = np.round((high_prices - min_price) / high_prices * 100, 1)\n",
    "\n",
    "    # Assuming filtered_df.index is a DatetimeIndex\n",
    "    filtered_df['days_from_start'] = (filtered_df.index - filtered_df.index[0]).days\n",
    "    date_started = filtered_df.index[0]\n",
    "\n",
    "\n",
    "    # Get the first date where drawdown equals diff\n",
    "    df_to_append = filtered_df[filtered_df[\"drawdown\"] == filtered_df[\"diff\"]].copy()\n",
    "    df_to_append.loc[:, \"Date_started\"] = date_started\n",
    "    df_to_append.index.rename(\"Date_ended\", inplace=True)\n",
    "\n",
    "    if df_to_append[\"drawdown\"].iloc[0] > 5:\n",
    "        corrections_df = pd.concat([corrections_df, df_to_append])\n",
    "\n",
    "# Optional: reset index after concatenation\n",
    "corrections_df = corrections_df.reset_index()\n",
    "corrections_df  = corrections_df[[ 'Date_started', 'Date_ended', 'drawdown', 'days_from_start']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46104e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_df[corrections_df[\"Date_started\"] == pd.Timestamp(\"1966-02-09\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bacfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_df[\"days_from_start\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bdf5d",
   "metadata": {},
   "source": [
    "# Question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77786f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/refs/heads/main/cohorts/2025/ha1_Amazon.csv\"\n",
    "earnings_df = pd.read_csv(url, delimiter=';')\n",
    "# Convert date column to datetime\n",
    "# Convert 'Earnings Date' to datetime\n",
    "# Strip time zone info if parsing fails\n",
    "earnings_df['Earnings Date'] = earnings_df['Earnings Date'].str.replace(r' [A-Z]{3}$', '', regex=True)\n",
    "earnings_df['Earnings Date'] = pd.to_datetime(earnings_df['Earnings Date'], format=\"%B %d, %Y at %I %p\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_eps(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    # Remove non-numeric characters except period and minus sign\n",
    "    cleaned = re.sub(r\"[^0-9\\.\\-]\", \"\", str(value))\n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Rename for simplicity\n",
    "earnings_df.rename(columns={\n",
    "    'Earnings Date': 'date',\n",
    "    'EPS Estimate': 'estimate',\n",
    "    'Reported EPS': 'actual'\n",
    "}, inplace=True)\n",
    "\n",
    "earnings_df['estimate'] = earnings_df['estimate'].apply(clean_eps)\n",
    "earnings_df['actual'] = earnings_df['actual'].apply(clean_eps)\n",
    "earnings_df = earnings_df.dropna(subset=['estimate', 'actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2cd05824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>Close_Day3</th>\n",
       "      <th>Close_Day1</th>\n",
       "      <th>2d_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-15</th>\n",
       "      <td>0.097917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-16</th>\n",
       "      <td>0.086458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-19</th>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-20</th>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.057319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-21</th>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.197088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>204.720001</td>\n",
       "      <td>200.990005</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>-0.018220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>205.699997</td>\n",
       "      <td>206.020004</td>\n",
       "      <td>205.699997</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-30</th>\n",
       "      <td>205.009995</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>205.009995</td>\n",
       "      <td>-0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-02</th>\n",
       "      <td>206.649994</td>\n",
       "      <td>205.699997</td>\n",
       "      <td>206.649994</td>\n",
       "      <td>-0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03</th>\n",
       "      <td>205.710007</td>\n",
       "      <td>205.009995</td>\n",
       "      <td>205.710007</td>\n",
       "      <td>-0.003403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7057 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            AMZN  Close_Day3  Close_Day1  2d_return\n",
       "Date                                                     \n",
       "1997-05-15    0.097917         NaN    0.097917        NaN\n",
       "1997-05-16    0.086458         NaN    0.086458        NaN\n",
       "1997-05-19    0.085417    0.097917    0.085417   0.146341\n",
       "1997-05-20    0.081771    0.086458    0.081771   0.057319\n",
       "1997-05-21    0.071354    0.085417    0.071354   0.197088\n",
       "...                ...         ...         ...        ...\n",
       "2025-05-28  204.720001  200.990005  204.720001  -0.018220\n",
       "2025-05-29  205.699997  206.020004  205.699997   0.001556\n",
       "2025-05-30  205.009995  204.720001  205.009995  -0.001415\n",
       "2025-06-02  206.649994  205.699997  206.649994  -0.004597\n",
       "2025-06-03  205.710007  205.009995  205.710007  -0.003403\n",
       "\n",
       "[7057 rows x 4 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = yf.download(\n",
    "    tickers = \"AMZN\", \n",
    "    end=date.today(),\n",
    "    interval = \"1d\")[\"Close\"]\n",
    "amazon['Close_Day3'] = amazon['AMZN'].shift(2)\n",
    "amazon['Close_Day1'] = amazon['AMZN']\n",
    "amazon['2d_return'] = amazon['Close_Day3'] / amazon['Close_Day1'] - 1\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4eddf7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive surprise dates: 36\n"
     ]
    }
   ],
   "source": [
    "earnings_df = earnings_df[earnings_df['actual'] > earnings_df['estimate']].copy()\n",
    "earnings_df = earnings_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of positive surprise dates: {len(earnings_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b4d798ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timezone from earnings dates (if present)\n",
    "earnings_df['date'] = earnings_df['date'].dt.tz_localize(None)\n",
    "\n",
    "# Ensure index is datetime and timezone-naive\n",
    "amazon.reset_index(inplace=True)\n",
    "amazon['Date'] = pd.to_datetime(amazon['Date'])\n",
    "amazon = amazon.set_index('Date')\n",
    "amazon.index = amazon.index.tz_localize(None)\n",
    "\n",
    "# Define the lookup function\n",
    "def find_next_trading_day(earn_date):\n",
    "    return amazon.index[amazon.index >= earn_date].min()\n",
    "\n",
    "# Apply to earnings dates\n",
    "earnings_df['trading_date'] = earnings_df['date'].apply(find_next_trading_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a41b01e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median 2-day return after positive surprises: -2.77%\n"
     ]
    }
   ],
   "source": [
    "# Merge to get 2-day return for earnings dates\n",
    "\n",
    "merged = pd.merge(\n",
    "    earnings_df,\n",
    "    amazon[['2d_return']],\n",
    "    left_on='trading_date',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "median_positive_surprise_return = merged['2d_return'].median() * 100\n",
    "print(f\"Median 2-day return after positive surprises: {median_positive_surprise_return:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7e6c8571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median 2-day return for all days: -0.17%\n"
     ]
    }
   ],
   "source": [
    "median_all_returns = amazon['2d_return'].median() * 100\n",
    "print(f\"Median 2-day return for all days: {median_all_returns:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc846259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
